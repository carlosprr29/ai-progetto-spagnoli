{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlosprr29/ai-progetto-spagnoli/blob/main/notebooks/03_2_BERT_Training_ISOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ksou17Mb1zaH"
      },
      "outputs": [],
      "source": [
        "# =================================================================\n",
        "# FILE 03.1: ISOT TRAINING DATASET + AUGMENTATION\n",
        "# =================================================================\n",
        "\n",
        "# 1. Facilities and Bookshops\n",
        "!pip install -q transformers datasets torch scikit-learn\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqsJZfhZ163_"
      },
      "outputs": [],
      "source": [
        "# 2. DATA LOADING AND BIAS CLEANING\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Paths (Ensure the names match your files in Drive)\n",
        "path_true = '/content/drive/MyDrive/Project_IA/data/True.csv'\n",
        "path_fake = '/content/drive/MyDrive/Project_IA/data/Fake.csv'\n",
        "\n",
        "df_true = pd.read_csv(path_true)\n",
        "df_fake = pd.read_csv(path_fake)\n",
        "\n",
        "df_true['label'] = 0 # Real\n",
        "df_fake['label'] = 1 # Fake\n",
        "\n",
        "# We combine and shuffle\n",
        "df = pd.concat([df_true, df_fake]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df = df.dropna(subset=[\"title\", \"text\"])\n",
        "\n",
        "def clean_bias_isot(text):\n",
        "    if not isinstance(text, str): return \"\"\n",
        "\n",
        "    # 1. REMOVE THE ENTIRE HEADER (Dateline)\n",
        "    # This regex searches from the beginning (^) to the first hyphen (-) or colon (:)\n",
        "    # that usually separates the city/agency from the actual content.\n",
        "    # It covers cases such as: \"WASHINGTON (Reuters) -\", \"SEATTLE/WASHINGTON -\", \"NEW YORK:\"\n",
        "    text = re.sub(r'^[^-:]*[-:]\\s*', '', text)\n",
        "\n",
        "    # 2. DELETE ANY REMAINING REFERENCES TO REUTERS\n",
        "    # In case it appears in the middle of the text or in capital letters\n",
        "    text = re.sub(r'\\bReuters\\b', 'the news agency', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # 3. OPTIONAL: DELETE THE FIRST SENTENCE IF IT IS VERY SHORT\n",
        "    # Sometimes there is rubbish left after the hyphen. If the first sentence has fewer than 3 words, we remove it.\n",
        "    sentences = text.split('. ')\n",
        "    if len(sentences) > 1 and len(sentences[0].split()) < 4:\n",
        "        text = '. '.join(sentences[1:])\n",
        "\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06nS9or32K8f"
      },
      "outputs": [],
      "source": [
        "# 3. DATA AUGMENTATION (A technique that involves creating artificial variations of your current data\n",
        "#(such as scrambling sentences or changing synonyms) so that the AI learns more general patterns and does not memorise the texts.)\n",
        "# -----------------------------------------------------------------\n",
        "def augment_text(text):\n",
        "    if not isinstance(text, str): return \"\"\n",
        "    sentences = text.split('. ')\n",
        "    if len(sentences) > 2:\n",
        "        random.shuffle(sentences) # We scrambled the sentences\n",
        "    return '. '.join(sentences)\n",
        "\n",
        "# we clean biases\n",
        "print(\"ðŸ§¹ Cleaning up biases from Reuters and Datelines in ISOT...\")\n",
        "df['text'] = df['text'].apply(clean_bias_isot)\n",
        "\n",
        "# 80/20 split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])\n",
        "\n",
        "# We apply Augmentation only to the training text column.\n",
        "train_df['text_aug'] = train_df['text'].apply(lambda x: augment_text(x) if random.random() > 0.5 else x)\n",
        "train_df['total_aug'] = train_df['title'] + \" \" + train_df['text_aug']\n",
        "test_df['total'] = test_df['title'] + \" \" + test_df['text']\n",
        "\n",
        "# Sampling to avoid burning RAM (ISOT is heavy)\n",
        "train_sample = train_df.sample(n=6000, random_state=42)\n",
        "test_sample = test_df.sample(n=1500, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmVX1otj2SKs"
      },
      "outputs": [],
      "source": [
        "# 4. REUSABLE TRAINING FUNCTION\n",
        "def train_model_isot(x_train, x_test, y_train, y_test, model_name):\n",
        "    print(f\"\\nðŸš€ Training: {model_name}\")\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "    # Tokenisation\n",
        "    train_enc = tokenizer(x_train.tolist(), truncation=True, padding=True, max_length=128)\n",
        "    test_enc = tokenizer(x_test.tolist(), truncation=True, padding=True, max_length=128)\n",
        "\n",
        "    class DatasetTorch(torch.utils.data.Dataset):\n",
        "        def __init__(self, encodings, labels):\n",
        "            self.encodings = encodings\n",
        "            self.labels = labels\n",
        "        def __getitem__(self, idx):\n",
        "            item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "            return item\n",
        "        def __len__(self): return len(self.labels)\n",
        "\n",
        "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=f\"./results_{model_name}\",\n",
        "        num_train_epochs=2,\n",
        "        per_device_train_batch_size=16,\n",
        "        fp16=True,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"no\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=DatasetTorch(train_enc, y_train.tolist()),\n",
        "        eval_dataset=DatasetTorch(test_enc, y_test.tolist()),\n",
        "        compute_metrics=lambda p: {\"accuracy\": accuracy_score(p.label_ids, np.argmax(p.predictions, axis=1))}\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    return model, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXCJU_9x2UvO",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# 4. PERFORMANCE OF THE ABLATION STUDY (ISOT)\n",
        "# MODEL A: Titles Only\n",
        "model_isot_tit, token_isot_tit = train_model_isot(\n",
        "    train_sample[\"title\"], test_sample[\"title\"],\n",
        "    train_sample[\"label\"], test_sample[\"label\"], \"ISOT_TITLES\"\n",
        ")\n",
        "model_isot_tit.save_pretrained('./model_isot_titles')\n",
        "token_isot_tit.save_pretrained('./model_isot_titles')\n",
        "\n",
        "# Connect and copy to Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import shutil\n",
        "# We copy it into the folder.\n",
        "shutil.copytree('./model_isot_titles', '/content/drive/MyDrive/Project_IA/model_isot_titles')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBek8wjx8umG",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# MODEL B: Title + Text (with Augmentation)\n",
        "model_isot_full, token_isot_full = train_model_isot(\n",
        "    train_sample[\"total_aug\"], test_sample[\"total\"],\n",
        "    train_sample[\"label\"], test_sample[\"label\"], \"ISOT_FULL_TEXT\"\n",
        ")\n",
        "\n",
        "model_isot_full.save_pretrained('./model_isot_full')\n",
        "token_isot_full.save_pretrained('./model_isot_full')\n",
        "\n",
        "# Connect and copy to Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import shutil\n",
        "# We copy it into the folder.\n",
        "shutil.copytree('./model_isot_full', '/content/drive/MyDrive/Project_IA/model_isot_full')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2BufK0t7F1d",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Auxiliary function to obtain the final accuracy cleanly\n",
        "def evaluate(model, tokeniser, texts, labels):\n",
        "    inputs = tokeniser(texts.tolist(), truncation=True, padding=True, max_length=128, return_tensors=\"pt\").to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
        "    return accuracy_score(labels, preds)\n",
        "\n",
        "# We calculate the actual percentages obtained.\n",
        "acc_isot_tit = evaluate(model_isot_tit, token_isot_tit, test_sample[\"title\"], test_sample[\"label\"])\n",
        "acc_isot_full = evaluate(model_isot_full, token_isot_full, test_sample[\"total\"], test_sample[\"label\"])\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"ðŸ“Š ABLATION STUDY SUMMARY (ISOT DATASET)\")\n",
        "print(\"=\"*40)\n",
        "print(f\"ðŸ”¹ Accuracy Titles Only:    {acc_isot_tit*100:.2f}%\")\n",
        "print(f\"ðŸ”¹ Accuracy Title + Text:  {acc_isot_full*100:.2f}%\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "dif_isot = (acc_isot_full - acc_isot_tit) * 100\n",
        "print(f\"âœ… Improvement in ISOT thanks to the text: {dif_isot:.2f}%\")\n",
        "print(\"=\"*40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7RweeQC7LYl",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# 6. COMPARATIVE CHART\n",
        "# ----------------------------------------------------------------\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "labels = ['ISOT Titles', 'ISOT title+Text']\n",
        "values = [acc_isot_tit, acc_isot_full]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "bars = plt.bar(labels, values, color=['#90e0ef', '#0077b6'])\n",
        "plt.ylim(0.85, 1.0)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Dataset ISOT')\n",
        "\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.005, f\"{yval*100:.2f}%\",\n",
        "             ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbYI3IkebUQX"
      },
      "source": [
        "# CONCLUSIONS\n",
        "Although the ISOT model has higher accuracy, it shows a strong style bias. In contrast, the WELFake model, despite having slightly lower accuracy, demonstrates better generalisation capabilities when dealing with news from diverse sources.\n",
        "\n",
        "The ISOT model is giving us 99.5%, which confirms our suspicion: the dataset has very strong structural biases that AI detects as shortcuts. That is why the fusion with WELFake that we are doing is vital, to force the model to be more critical and not so 'optimistic'.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}