{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlosprr29/ai-progetto-spagnoli/blob/main/notebooks/Baseline_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup Environment"
      ],
      "metadata": {
        "id": "htwLKrpg4YKh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YL-1SMSM4LAE",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "##Celda de Instalaci√≥n y carga\n",
        "!pip install -q datasets pandas scikit-learn\n",
        "\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Descargamos el dataset WELFake\n",
        "print(\"‚è≥ Descargando dataset...\")\n",
        "dataset_raw = load_dataset(\"davanstrien/WELFake\")\n",
        "df = pd.DataFrame(dataset_raw['train'])\n",
        "\n",
        "# Limpieza r√°pida: quitamos filas que no tengan texto o t√≠tulo\n",
        "df = df.dropna(subset=['title', 'text'])\n",
        "print(f\"‚úÖ Dataset cargado: {len(df)} filas.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚è≥ Descargando dataset...\n",
        "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning:\n",
        "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
        "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
        "You will be able to reuse this secret in all of your notebooks.\n",
        "Please note that authentication is recommended but still optional to access public models or datasets.\n",
        "  warnings.warn(\n",
        "README.md:\n",
        "‚Äá2.37k/?‚Äá[00:00<00:00,‚Äá141kB/s]\n",
        "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
        "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
        "data/train-00000-of-00001-290868f0a36350(‚Ä¶):‚Äá100%\n",
        "‚Äá152M/152M‚Äá[00:01<00:00,‚Äá105MB/s]\n",
        "Generating‚Äátrain‚Äásplit:‚Äá100%\n",
        "‚Äá72134/72134‚Äá[00:02<00:00,‚Äá32466.99‚Äáexamples/s]\n",
        "‚úÖ Dataset cargado: 71537 filas."
      ],
      "metadata": {
        "id": "uXxaxL0pXa42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Celda de Divisi√≥n de Datos\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividimos el dataset (80% entrenamiento, 20% prueba)\n",
        "# 'stratify' asegura que haya la misma proporci√≥n de noticias reales y fakes en ambos grupos\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
        "\n",
        "print(f\"Datos para entrenar: {len(train_df)}\")\n",
        "print(f\"Datos para evaluar: {len(test_df)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "p2Qa5B7XQ-OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datos para entrenar: 57229\n",
        "Datos para evaluar: 14308"
      ],
      "metadata": {
        "id": "_s__r-JxXYBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Experimento 1: Baseline con Regresi√≥n Log√≠stica\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Definimos la funci√≥n de entrenamiento y evaluaci√≥n\n",
        "def entrenar_y_evaluar(X_train, X_test, y_train, y_test, nombre_experimento):\n",
        "    # 1. Creamos el modelo (TF-IDF + Regresi√≥n Log√≠stica)\n",
        "    # TF-IDF convierte palabras en n√∫meros seg√∫n su importancia (max_features evita que sea muy pesado)\n",
        "    pipeline = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(stop_words='english', max_features=5000)),\n",
        "        ('clf', LogisticRegression(max_iter=1000))\n",
        "    ])\n",
        "\n",
        "    # 2. Entrenamos\n",
        "    print(f\"\\nüöÄ Entrenando modelo para: {nombre_experimento}...\")\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # 3. Predecimos\n",
        "    predicciones = pipeline.predict(X_test)\n",
        "\n",
        "    # 4. Resultados\n",
        "    acc = accuracy_score(y_test, predicciones)\n",
        "    print(f\"‚úÖ Precisi√≥n ({nombre_experimento}): {acc:.4f}\")\n",
        "    print(classification_report(y_test, predicciones))\n",
        "\n",
        "    return acc\n",
        "\n",
        "# --- EJECUCI√ìN DEL ESTUDIO DE ABLACI√ìN ---\n",
        "\n",
        "# CASO 1: Solo con el t√≠tulo\n",
        "acc_titulos = entrenar_y_evaluar(\n",
        "    train_df['title'], test_df['title'],\n",
        "    train_df['label'], test_df['label'],\n",
        "    \"SOLO T√çTULOS\"\n",
        ")\n",
        "\n",
        "# CASO 2: T√≠tulo + Texto (Creamos la columna 'total' justo antes)\n",
        "train_df['total'] = train_df['title'] + \" \" + train_df['text']\n",
        "test_df['total'] = test_df['title'] + \" \" + test_df['text']\n",
        "\n",
        "acc_completo = entrenar_y_evaluar(\n",
        "    train_df['total'], test_df['total'],\n",
        "    train_df['label'], test_df['label'],\n",
        "    \"TEXTO COMPLETO\"\n",
        ")"
      ],
      "metadata": {
        "id": "RmpFWfu3Rbsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üöÄ Entrenando modelo para: SOLO T√çTULOS...\n",
        "‚úÖ Precisi√≥n (SOLO T√çTULOS): 0.8937\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.90      0.88      0.89      7006\n",
        "           1       0.89      0.90      0.90      7302\n",
        "\n",
        "    accuracy                           0.89     14308\n",
        "   macro avg       0.89      0.89      0.89     14308\n",
        "weighted avg       0.89      0.89      0.89     14308\n",
        "\n",
        "\n",
        "üöÄ Entrenando modelo para: TEXTO COMPLETO...\n",
        "‚úÖ Precisi√≥n (TEXTO COMPLETO): 0.9436\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.95      0.93      0.94      7006\n",
        "           1       0.94      0.95      0.95      7302\n",
        "\n",
        "    accuracy                           0.94     14308\n",
        "   macro avg       0.94      0.94      0.94     14308\n",
        "weighted avg       0.94      0.94      0.94     14308"
      ],
      "metadata": {
        "id": "J1O5i3I8XTQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Eficacia del Baseline:** Un 94.36% en texto completo es una marca alt√≠sima. Esto indica que el dataset WELFake tiene patrones de palabras muy claros que permiten distinguir noticias reales de fakes con facilidad.\n",
        "\n",
        "**Ablation Study (Hallazgo inicial)**: Hay una diferencia de 5 puntos (89% vs 94%).\n",
        "\n",
        "**Conclusi√≥n:** Aunque el t√≠tulo por s√≠ solo es muy informativo, el cuerpo de la noticia aporta un contexto necesario para captar un 5% extra de casos que el titular no revela.\n",
        "\n",
        "**El reto para BERT:** Vuestro Baseline es tan bueno que el desaf√≠o ahora no es solo \"superar\" el 94%, sino ver si BERT es capaz de entender noticias m√°s ambiguas donde las palabras clave no son tan obvias.\n"
      ],
      "metadata": {
        "id": "zE16wY-TXM0f"
      }
    }
  ]
}