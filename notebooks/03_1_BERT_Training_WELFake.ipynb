{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlosprr29/ai-progetto-spagnoli/blob/main/notebooks/03_1_BERT_Training_WELFake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets torch scikit-learn\n",
        "!pip install --upgrade transformers"
      ],
      "metadata": {
        "id": "Le1bTSC90kPb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "VefdOtW30pSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "dataset = load_dataset(\"davanstrien/WELFake\")\n",
        "df = dataset[\"train\"].to_pandas()\n",
        "\n",
        "# Clean\n",
        "df = df.dropna(subset=[\"title\", \"text\"])\n",
        "\n",
        "# Stratified 80/20 division\n",
        "train_df, test_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df[\"label\"]\n",
        ")"
      ],
      "metadata": {
        "id": "JsGYeuy10wes",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bert(train_text, test_text, train_y, test_y, name):\n",
        "\n",
        "    print(f\"\\n Training BERT for: {name}\")\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "    train_encodings = tokenizer(\n",
        "        train_text.tolist(),\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "    test_encodings = tokenizer(\n",
        "        test_text.tolist(),\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "    class DatasetTorch(torch.utils.data.Dataset):\n",
        "        def __init__(self, encodings, labels):\n",
        "            self.encodings = encodings\n",
        "            self.labels = labels\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "            return item\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.labels)\n",
        "\n",
        "    train_dataset = DatasetTorch(train_encodings, train_y.tolist())\n",
        "    test_dataset = DatasetTorch(test_encodings, test_y.tolist())\n",
        "\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        \"bert-base-uncased\",\n",
        "        num_labels=2\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results\",\n",
        "        num_train_epochs=2, # 3 is more robust\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        fp16=True,\n",
        "        do_eval=True,\n",
        "        logging_dir=\"./logs\",\n",
        "        save_strategy=\"no\",\n",
        "        load_best_model_at_end=False\n",
        "    )\n",
        "\n",
        "    def compute_metrics(eval_pred):\n",
        "        logits, labels = eval_pred\n",
        "        preds = np.argmax(logits, axis=1)\n",
        "        acc = accuracy_score(labels, preds)\n",
        "        return {\"accuracy\": acc}\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=test_dataset,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    predictions = trainer.predict(test_dataset)\n",
        "    preds = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "    acc = accuracy_score(test_y, preds)\n",
        "\n",
        "    print(f\"\\n✅ Accuracy ({name}): {acc:.4f}\")\n",
        "    print(classification_report(test_y, preds))\n",
        "\n",
        "    #We return the rating, the trained AI, and the translator that converts\n",
        "    #your words into the specific numbers that model understands.\n",
        "    return acc, model, tokenizer"
      ],
      "metadata": {
        "id": "cePEH5fN1SOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We carry out the training\n",
        "acc_titulo, model_tit, token_tit = train_bert(\n",
        "    train_df[\"title\"],\n",
        "    test_df[\"title\"],\n",
        "    train_df[\"label\"],\n",
        "    test_df[\"label\"],\n",
        "    \"TITLES ONLY\"\n",
        ")\n",
        "\n",
        "# We save the trained AI and the translator\n",
        "model_tit.save_pretrained('./model_WELFake_titles')\n",
        "token_tit.save_pretrained('./model_WELFake_titles')\n",
        "\n",
        "# Connect and copy to Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import shutil\n",
        "# We copy it into the folder.\n",
        "shutil.copytree('./model_WELFake_titles', '/content/drive/MyDrive/Project_IA/model_WELFake_titles')"
      ],
      "metadata": {
        "id": "omilsl7g1e5s",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We take a small sample so as not to overload the RAM.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df_sample, _ = train_test_split(\n",
        "    train_df,\n",
        "    train_size=6000,\n",
        "    stratify=train_df[\"label\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "test_df_sample, _ = train_test_split(\n",
        "    test_df,\n",
        "    train_size=1500,\n",
        "    stratify=test_df[\"label\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_df = train_df_sample\n",
        "test_df = test_df_sample\n",
        "\n",
        "\n",
        "# We carry out the training\n",
        "train_df[\"total\"] = train_df[\"title\"] + \" \" + train_df[\"text\"]\n",
        "test_df[\"total\"] = test_df[\"title\"] + \" \" + test_df[\"text\"]\n",
        "\n",
        "acc_total, model_full, token_full = train_bert(\n",
        "    train_df[\"total\"],\n",
        "    test_df[\"total\"],\n",
        "    train_df[\"label\"],\n",
        "    test_df[\"label\"],\n",
        "    \"TITLE + TEXT\"\n",
        ")\n",
        "\n",
        "# We save the trained AI and the translator.\n",
        "model_full.save_pretrained('./model_WELFake_full')\n",
        "token_full.save_pretrained('./model_WELFake_full')\n",
        "\n",
        "# Connect and copy to Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import shutil\n",
        "# We copy it to Drive.\n",
        "shutil.copytree('./model_WELFake_full', '/content/drive/MyDrive/Project_IA/model_WELFake_full')"
      ],
      "metadata": {
        "id": "2xvvh_VS7cWg",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" RESULTS OF THE ABLATION STUDY\")\n",
        "print(\"-\" * 30)\n",
        "# Replace acc_title with the value given to you during the first training session\n",
        "print(f\"Accuracy (Titles Only):   {0.9584:.4f}\")\n",
        "print(f\"Accuracy (Title + Text): {0.9833:.4f}\")\n",
        "\n",
        "difference = (0.9833 - 0.9584) * 100\n",
        "print(\"-\" * 30)\n",
        "print(f\"✅ Conclusion: Adding the full text improves the model by {difference:.2f}%\")"
      ],
      "metadata": {
        "id": "nw_Ltr5m7gTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# --- DATA ---\n",
        "acc_real_titles = 0.9584\n",
        "acc_real_text = 0.9833\n",
        "\n",
        "labels = ['Titles Only', 'Title + Text']\n",
        "values = [acc_real_titles, acc_real_text]\n",
        "\n",
        "# --- CREATE GRAPH ---\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "bars = ax.bar(labels, values, color=['#A0C4FF', '#023E8A'])\n",
        "\n",
        "# Visual settings\n",
        "ax.set_ylim(0.85, 1.0)\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Impact of Full Text on Detection (Ablation Study)')\n",
        "\n",
        "# Add the percentages above the bars.\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, yval + 0.005, f\"{yval*100:.2f}%\",\n",
        "            ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cz0XcNCeWu8Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}