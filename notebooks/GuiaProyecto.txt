üìã Resumen General del Proyecto
El objetivo es crear un detector de Fake News usando el modelo BERT. Lo especial de vuestro trabajo es el Ablation Study: demostrar si BERT es m√°s listo analizando solo los titulares o analizando la noticia entera.

En un proyecto de IA, los pasos suelen ser siempre los mismos y dependen el uno del otro. Los n√∫meros marcan las etapas:

01_EDA_WELFake.ipynb: Primero entiendo y limpio los datos (lo que acabas de hacer).

02_Baseline.ipynb: Despu√©s establezco la marca a batir con el modelo simple.

03_BERT_Training.ipynb: Luego entreno el modelo pesado.

04_Evaluation.ipynb: Finalmente comparo todo y saco gr√°ficas finales.

Las fases son:

Preprocesamiento: Limpiar el dataset WELFake y preparar los textos.

Entrenamiento A (Base): Entrenar a BERT solo con los T√≠tulos.

Entrenamiento B (Completo): Entrenar a BERT con T√≠tulo + Cuerpo.

Evaluaci√≥n: Comparar Accuracy, F1-Score y MCC para ver cu√°l gana.

Documentaci√≥n: Explicar por qu√© un modelo es mejor que el otro.

ü§ù Divisi√≥n del Trabajo (Para no solaparse)
La mejor forma de trabajar en GitHub/Colab sin "machacar" el c√≥digo del otro es dividirse por m√≥dulos o experimentos. Cada uno deber√≠a tener su propio archivo Notebook al principio.

Integrante A: "El Especialista en Datos y Baseline"
Tarea 1: Crear el Notebook de limpieza de datos (01_Data_Cleaning.ipynb). Se encarga de descargar WELFake y dejar los archivos de Train/Test listos.

Tarea 2: Implementar un modelo sencillo (Baseline). Por ejemplo, una Regresi√≥n Log√≠stica o un clasificador simple.

¬øPor qu√©? Para tener una cifra con la que comparar a BERT. Si BERT saca un 90%, pero el modelo simple saca un 88%, vuestro trabajo explicar√° que BERT "no compensa" tanto por el tiempo que tarda.

Tarea 3: Redactar la parte t√©cnica de la documentaci√≥n (qu√© librer√≠as se usaron).

Integrante B: "El Ingeniero de BERT y Entrenamiento"
Tarea 1: Crear el Notebook principal de BERT (02_Training_BERT.ipynb). Se encarga de la Tokenizaci√≥n.

Tarea 2: Entrenar el modelo con la variante de Solo T√≠tulos.

Tarea 3: Configurar el bucle de entrenamiento (Epochs, Learning Rate).

Tarea 4: Graficar las curvas de p√©rdida (Loss) y precisi√≥n (Accuracy).

üöÄ C√≥mo trabajar sin errores de GitHub
Para evitar el famoso error de "conflicto" en GitHub:

Nombres de archivos distintos: No edit√©is los dos el mismo .ipynb. Si Andrea est√° trabajando en entrenamiento_v1.ipynb, el compa√±ero debe trabajar en entrenamiento_v2.ipynb o en un archivo de an√°lisis.

Comunicaci√≥n por cada "Commit": Cuando termines una parte importante, avisa: "Andrea, ya he subido la carga de datos a GitHub, puedes usarla".

Modularizar: Una vez que el "Integrante A" termine de limpiar los datos, puede guardar el resultado en un archivo .csv peque√±o. As√≠ el "Integrante B" solo tiene que cargar ese archivo y no repetir todo el proceso.

¬øCu√°l es el siguiente paso para hoy?
Os recomiendo que decid√°is qui√©n va a ser el Integrante A y qui√©n el B.

Si eres la A: Deber√≠as empezar a crear el c√≥digo para limpiar el dataset y dividirlo en Train/Test.

Si eres la B: Deber√≠as investigar qu√© versi√≥n de BERT usar (yo te recomiendo bert-base-uncased por ser ligera y r√°pida).
