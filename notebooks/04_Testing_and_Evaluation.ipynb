{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlosprr29/ai-progetto-spagnoli/blob/main/notebooks/04_Testing_and_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. INSTALLATION AND BOOKSTORES\n",
        "!pip install -q transformers datasets torch scikit-learn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import re\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n"
      ],
      "metadata": {
        "id": "sPghDcD6e0Bk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. CONNECTION TO DRIVE AND CHARGING OF ALL MODELS\n",
        "# -----------------------------------------------------------------\n",
        "drive.mount('/content/drive')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"â³ Loading all trained models... (this may take a while)\")\n",
        "\n",
        "# WELFake load\n",
        "m_welfake = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/Project_IA/model_WELFake_full').to(device)\n",
        "t_welfake = BertTokenizer.from_pretrained('/content/drive/MyDrive/Project_IA/model_WELFake_full')\n",
        "m_welfake_tit = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/Project_IA/model_WELFake_titles').to(device)\n",
        "t_welfake_tit = BertTokenizer.from_pretrained('/content/drive/MyDrive/Project_IA/model_WELFake_titles')\n",
        "\n",
        "# ISOT load\n",
        "m_isot = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/Project_IA/model_isot_full').to(device)\n",
        "t_isot = BertTokenizer.from_pretrained('/content/drive/MyDrive/Project_IA/model_isot_full')\n",
        "m_isot_tit = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/Project_IA/model_isot_titles').to(device)\n",
        "t_isot_tit = BertTokenizer.from_pretrained('/content/drive/MyDrive/Project_IA/model_isot_titles')\n",
        "\n",
        "# FUSION load\n",
        "m_fusion = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/Project_IA/model_fusion_full').to(device)\n",
        "t_fusion = BertTokenizer.from_pretrained('/content/drive/MyDrive/Project_IA/model_fusion_full')\n",
        "m_fusion_tit = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/Project_IA/model_fusion_titles').to(device)\n",
        "t_fusion_tit = BertTokenizer.from_pretrained('/content/drive/MyDrive/Project_IA/model_fusion_titles')"
      ],
      "metadata": {
        "id": "fRBrwUDTIPEK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------\n",
        "# 2. INTERACTIVE CONTROL PANEL (@title)\n",
        "# -----------------------------------------------------------------\n",
        "# @title ðŸ” Control Panel: Fake News Detector Pro\n",
        "\n",
        "test_title = \"Vladimir Putin, trapped by his own logic of war\" # @param {type:\"string\"}\n",
        "test_text = \"Four years after launching his war against Ukraine, Vladimir Putin still has not secured the victory he had hoped for. When he sent his troops to attack Russia's neighbor on February 24, 2022, the Russian leader claimed his aim was to denazify and demilitarize a country whose very existence he denies. Seven months earlier, he had laid out his ambitions in an essay titled, On the Historical Unity of Russians and Ukrainians.This essay, published on the Kremlin's official website, clearly announced his special military operation, supposed to bring a change of power in Kyiv and demonstrate the greatness of eternal Russia in the face of what he viewed as an aggressive and decadent West. That objective remains far from achieved: Volodymyr Zelensky, the Ukrainian president, is still in office, and European support for Ukraine has held firm.\" # @param {type:\"string\"}\n",
        "threshold = 0.65 # @param {type:\"slider\", min:0.5, max:0.95, step:0.05}\n",
        "model_to_use = \"Fusion\" # @param [\"WELFake\", \"ISOT\", \"Fusion\"]\n",
        "\n",
        "def detect_pro(title, text, sensitivity):\n",
        "    # Dynamic selection of model pairs (Titles and Full) according to the parameter\n",
        "    if model_to_use == \"WELFake\":\n",
        "        m_f, t_f = m_welfake, t_welfake\n",
        "        m_t, t_t = m_welfake_tit, t_welfake_tit\n",
        "    elif model_to_use == \"ISOT\":\n",
        "        m_f, t_f = m_isot, t_isot\n",
        "        m_t, t_t = m_isot_tit, t_isot_tit\n",
        "    elif model_to_use == \"Fusion\":\n",
        "        m_f, t_f = m_fusion, t_fusion\n",
        "        m_t, t_t = m_fusion_tit, t_fusion_tit\n",
        "\n",
        "    classes = {0: \"âœ… REAL\", 1: \"ðŸš¨ FAKE\"}\n",
        "\n",
        "    # A. Model Prediction Headlines\n",
        "    inputs_tit = t_t(title, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n",
        "    m_t.eval()\n",
        "    with torch.no_grad():\n",
        "        out_tit = m_t(**inputs_tit)\n",
        "        prob_tit = torch.nn.functional.softmax(out_tit.logits, dim=1)\n",
        "        pred_tit = torch.argmax(prob_tit, dim=1).item()\n",
        "        conf_tit = prob_tit[0][pred_tit].item()\n",
        "\n",
        "    # B. Full Text Model Prediction\n",
        "    input_combined = title + \" \" + text\n",
        "    inputs_full = t_f(input_combined, return_tensors=\"pt\", truncation=True, padding=True, max_length=256).to(device)\n",
        "    m_f.eval()\n",
        "    with torch.no_grad():\n",
        "        out_full = m_f(**inputs_full)\n",
        "        prob_full = torch.nn.functional.softmax(out_full.logits, dim=1)\n",
        "        # Here we use the probability of FAKE (class 1) for the threshold logic.\n",
        "        prob_fake_val = prob_full[0][1].item()\n",
        "        pred_full = torch.argmax(prob_full, dim=1).item()\n",
        "\n",
        "    # C. Threshold logic for final verdict (based on Full Text)\n",
        "    if prob_fake_val >= sensitivity:\n",
        "        result = \"ðŸš¨ FAKE NEWS\"\n",
        "        colour = \"\\033[91m\"\n",
        "    elif prob_fake_val <= (1 - sensitivity):\n",
        "        result = \"âœ… REAL\"\n",
        "        colour = \"\\033[92m\"\n",
        "    else:\n",
        "        result = \"ðŸ¤”DOUBTFUL / INCONCLUSIVE\"\n",
        "        colour = \"\\033[93m\"\n",
        "\n",
        "    # D. Report\n",
        "    print(\"\\n\" + \"â•\"*60)\n",
        "    print(f\"ðŸ“Š COMPARATIVE VERIFICATION REPORT ({model_to_use.upper()})\")\n",
        "    print(\"â•\"*60)\n",
        "    print(f\"ðŸ“° HEADLINE: {title[:85]}...\")\n",
        "    print(f\"ðŸ¤– TITLES ONLY:   {classes[pred_tit]} ({conf_tit*100:.2f}% trust)\")\n",
        "    print(f\"ðŸ¤– TEXTO COMPLETO: {colour}{result}\\033[0m (Score Fake: {prob_fake_val*100:.2f}%)\")\n",
        "    print(f\"âš™ï¸  Current threshold:  {sensitivity}\")\n",
        "    print(\"â•\"*60)\n",
        "    if pred_tit != pred_full and result != \"ðŸ¤” DOUBTFUL / INCONCLUSIVE\":\n",
        "        print(\"ðŸ“¢ NOTE: The full text has corrected the prediction in the title.\")\n",
        "\n",
        "# Run the comparative detector with the news item from the panel\n",
        "detect_pro(test_title, test_text, threshold)"
      ],
      "metadata": {
        "id": "XrLSZXfNe1Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_battery(title, text):\n",
        "    \"\"\"\n",
        "    ALWAYS run the prediction on all three systems\n",
        "    and display the compared results.\n",
        "    \"\"\"\n",
        "    global model_to_use # We use the exact name of your variable.\n",
        "\n",
        "    # We keep the original model to restore it later.\n",
        "    original_selection = model_to_use\n",
        "\n",
        "    # List with the exact names that your 'if' expects within detect_pro\n",
        "    models = [\"WELFake\", \"ISOT\", \"Fusion\"]\n",
        "\n",
        "    print(\"\\n\" + \"â•\"*65)\n",
        "    print(f\"ðŸ”Ž TRIPLE COMPARATIVE ANALYSIS\")\n",
        "    print(f\"ðŸ“° HEADLINE: {title[:90]}...\")\n",
        "    print(\"â•\"*65)\n",
        "\n",
        "    # Loop that runs through each model\n",
        "    for m in models:\n",
        "        model_to_use = m\n",
        "        # We call your detect_pro function using 'threshold' (which is what it is called in your panel).\n",
        "        detect_pro(title, text, threshold)\n",
        "\n",
        "    # We restored the original model.\n",
        "    model_to_use = original_selection\n",
        "    print(\"â•\"*65 + \"\\n\")"
      ],
      "metadata": {
        "id": "xubldmhFf1UW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#REAL NEWS FROM LE MONDE (FRENCH NEWSPAPER). URL:https://www.lemonde.fr/en/opinion/article/2026/02/23/vladimir-putin-trapped-by-his-own-logic-of-war_6750782_23.html\n",
        "tit_1 = \"Vladimir Putin, trapped by his own logic of war\"\n",
        "txt_1 = \"Four years after launching his war against Ukraine, Vladimir Putin still has not secured the victory he had hoped for. When he sent his troops to attack Russia's neighbor on February 24, 2022, the Russian leader claimed his aim was to denazify and demilitarize a country whose very existence he denies. Seven months earlier, he had laid out his ambitions in an essay titled, On the Historical Unity of Russians and Ukrainians.This essay, published on the Kremlin's official website, clearly announced his special military operation, supposed to bring a change of power in Kyiv and demonstrate the greatness of eternal Russia in the face of what he viewed as an aggressive and decadent West. That objective remains far from achieved: Volodymyr Zelensky, the Ukrainian president, is still in office, and European support for Ukraine has held firm.\"\n",
        "\n",
        "test_battery(tit_1, txt_1)"
      ],
      "metadata": {
        "id": "3MBazS7-lCJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FAKE NEWS FROM theonion.com (The world's leading source of humorous fake news in English) URL:https://theonion.com/u-s-tourists-advised-to-temporarily-avoid-shootouts-with-mexican-drug-cartels/\n",
        "tit_2 = \"NASA Delays Space Walk After It Starts Snowing In Outer Space\"\n",
        "txt_2 = \"With no choice but to suspend the planned outing and await more favorable conditions, NASA announced Wednesday it had delayed a space walk after a heavy snow began to fall in outer space. â€œUnfortunately, a front has moved into our solar system, causing a severe blizzard that forced us to postpone this morningâ€™s scheduled space walk,â€ said NASA administrator Bill Nelson, who observed that four to five feet of snow had accumulated across much of the galaxy and that it was â€œquite blustery out there,â€ making it too difficult for astronauts to replace a malfunctioning antenna on the International Space Station. â€œOnce the weather clears up, weâ€™ll send our crew on a space walk with shovels and a bag of rock salt, and ensure the astronauts scrape off the windshield of their return spacecraft. In the meantime, weâ€™ve ordered them to cozy up and build a fire inside the ISS.â€ At press time, NASA officials confirmed the treacherous condition had caused a capsule full of space tourists to skid out of Earthâ€™s orbit and crash into the sun.\"\n",
        "\n",
        "test_battery(tit_2, txt_2)\n",
        "\n",
        "#NDON'T GET THE SATIRICAL TONE, THE HEADLINE LITERALLY SAYS: \"La NASA retrasa una caminata espacial tras empezar a nevar en el espacio exterior\""
      ],
      "metadata": {
        "id": "CDGC5TDZx6W0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#REAL NEWS THE NEW YORK TIMES. URL: https://www.nytimes.com/2026/02/23/world/americas/el-mencho-mexico-cartel-military-raid.html\n",
        "tit_3 = \"Mexican Forces Say They Tracked El Mencho to Cabin by Following His Lover\"\n",
        "txt_3 = \"To find Mexicoâ€™s most-wanted kingpin, security officials said, they did not follow the money or the trail of drugs. Instead, they said they followed his lover.It was she, the authorities said, who led them into the wooded mountains of Jalisco state, to the cabin where Nemesio Oseguera Cervantes â€” the notorious cartel leader known as El Mencho â€” was hiding since at least Friday.Quickly, a high-stakes plan was in motion to capture the head of the Jalisco New Generation Cartel, a man long considered one of the countryâ€™s most ruthless criminal figures, Mexican officials said Monday during a news conference.The operation culminated in a vicious firefight that killed several suspected cartel members, and by Sunday morning, Mr. Oseguera was dead after being fatally wounded in a shootout with Mexican authorities, the government said.\"\n",
        "\n",
        "test_battery(tit_3, txt_3)\n",
        "\n",
        "#ALL SYSTEMS ARE CORRECT"
      ],
      "metadata": {
        "id": "nRDhtF8buEfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#REAL NEWS THE NEW YORK TIMES. URL: https://www.nytimes.com/2026/02/24/world/europe/russia-ukraine-war-future.html\n",
        "tit_4 = \"How Russia Put Its Future at Risk by Remaking Its Economy for War\"\n",
        "txt_4 = \"For four years, President Vladimir V. Putin of Russia has made the war against Ukraine the lodestar of his every move. The single-minded approach has helped Mr. Putin salvage what began as a disastrous invasion, get his troops back on the front foot and dictate demands in peace talks mediated by Washington. But his stubborn pursuit of the war has come at a huge cost. It has killed or wounded as many as 1.2 million Russians, by some estimates, while reordering Russiaâ€™s economy and society in ways that many economists believe jeopardize the nationâ€™s future.â€œYou have lots of money spent on tanks, shells, bombs, military benefits and other things â€” no long-lasting value, nothing that works on what we call development,â€ said Alexandra Prokopenko, a former Russian central bank official who is now a fellow at the Carnegie Russia Eurasia Center in Berlin.\"\n",
        "\n",
        "test_battery(tit_4, txt_4)"
      ],
      "metadata": {
        "id": "CnYIqtTguqKX",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FAKE NEWS FROM SNOPES.COM. URL: https://www.snopes.com/fact-check/swift-kelce-donate-baby-cancer/\n",
        "tit_5 = \"TAYLOR SWIFT AND TRAVIS KELCE SPENT 300,000 USD TO FIGHT FOR THE LIFE OF A 2-YEAR-OLD BABY WITH BRAIN CANCER â€” AND ANNOUNCED THE PLAN TO BUILD THE LARGEST FREE ORPHANAGE IN THE UNITED STATES WORTH 80 MILLION USD.\"\n",
        "txt_5 = \"Not a stage, not an award show, not the dazzling lights of Hollywood â€” what silenced America today was the compassion of two people standing at the center of the world. Within 24 hours, Taylor Swift and Travis Kelce quietly covered the entire 300,000 USD medical cost to save a 2-year-old girl battling brain cancer. That silent yet powerful act made social media explode, as millions witnessed a rare moment of kindness in a chaotic era. But the biggest shock was still to come. Immediately after the information was confirmed, the couple announced the plan to build the largest free orphanage in the United States, an 80-million-USD project for children without shelter and those in vulnerable situations. Not an empty promise â€” but a commitment, a concrete step toward real change.\"\n",
        "\n",
        "test_battery(tit_5, txt_5)"
      ],
      "metadata": {
        "id": "H0kUkJNVwcmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FAKE NEWS FROM THEONION.COM URL: https://theonion.com/potomac-river-flooded-with-240-million-gallons-of-sewage/\n",
        "tit_6 = \"Potomac River Flooded With 240 Million Gallons Of Sewage\"\n",
        "txt_6 = \"The Potomac River, a waterway that winds through the nationâ€™s capital, is in the midst of an ecological crisis after one of the largest sewage spills in U.S. history, with over 240 million gallons of raw human waste threatening the health of the river and the safety of those who depend on it. What do you think?\"\n",
        "\n",
        "test_battery(tit_6, txt_6)"
      ],
      "metadata": {
        "id": "kYZ2uCkfw3g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… The Good (Strengths)\n",
        "Effectiveness in Real News: All three models show excellent accuracy in news from serious media outlets (NYT, Le Monde). They perfectly detect informative and neutral styles.\n",
        "\n",
        "Full Text Correction: The \"Full Text\" model has been shown to often correct the \"Headlines\" model. This shows that AI does not just focus on clickbait but also analyses the structure of the body of the message.\n",
        "\n",
        "Robustness of the Fusion Model: In dubious news items, the Master model tends to be more balanced, avoiding the extreme verdicts of the other two and offering greater generalisation capacity.\n",
        "\n",
        "âŒ The Bad (Weaknesses)\n",
        "\n",
        "Vulnerability to Satire: The system \"falls\" into the trap of media outlets such as The Onion. By using grammatically perfect and serious language, the ISOT model classifies it as Real, demonstrating that AI confuses \"professional form\" with \"truth.\"\n",
        "\n",
        "Lack of \"Common Sense\": The models do not know that it is physically impossible for it to snow in space. This confirms that BERT is a linguistic expert, but has no knowledge of the real world or the laws of physics.\n",
        "\n",
        "Stylistic Bias: The system remains sensitive to capital letters and emotional language (Taylor Swift case). If a fake news story is very well written, it is highly likely to fool the AI.\n"
      ],
      "metadata": {
        "id": "VU3VKoxdMm1e"
      }
    }
  ]
}